{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "366960a5-fc46-4de8-a50a-4acb5c405f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4960f45-4185-4cf6-9a1d-f111930d7ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from typing import Dict, List, Optional, Union, cast\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "#ignore all warnings, it's all good, trust me\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d01fc2f-1eca-4428-b6ce-cd9b102ffb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prepare_github as prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2244c507-90f8-4916-ae01-ddbdc9858b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace 'your_github_token' and 'your_github_username' with your GitHub token and username\n",
    "github_token = ''\n",
    "github_username = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9df65390-5d46-41ad-a084-4562a6e204e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"Authorization\": f\"token {github_token}\", \"User-Agent\": github_username}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d453713-76eb-45a3-800f-01796be43d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if headers[\"Authorization\"] == \"token \" or headers[\"User-Agent\"] == \"\":\n",
    "    raise Exception(\n",
    "        \"You need to replace 'your_github_token' and 'your_github_username' with your actual GitHub token and username\"\n",
    "    )\n",
    "\n",
    "def github_api_request(url: str) -> Union[List, Dict]:\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response_data = response.json()\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            f\"Error response from github api! status code: {response.status_code}, \"\n",
    "            f\"response: {json.dumps(response_data)}\"\n",
    "        )\n",
    "    return response_data\n",
    "\n",
    "def get_repo_language(repo: str) -> str:\n",
    "    url = f\"https://api.github.com/repos/{repo}\"\n",
    "    repo_info = github_api_request(url)\n",
    "    if isinstance(repo_info, dict):\n",
    "        return repo_info.get(\"language\", \"\")\n",
    "    raise Exception(\n",
    "        f\"Expecting a dictionary response from {url}, instead got {json.dumps(repo_info)}\"\n",
    "    )\n",
    "\n",
    "def get_readme_contents(repo: str) -> str:\n",
    "    url = f\"https://api.github.com/repos/{repo}/readme\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 404:  # handle not found error\n",
    "        return \"\"  # return empty string or whatever default value you prefer\n",
    "    readme_info = response.json()\n",
    "    if isinstance(readme_info, dict):\n",
    "        readme_text = requests.get(readme_info.get('download_url', '')).text\n",
    "        return readme_text\n",
    "    return \"\"\n",
    "\n",
    "def get_top_100_repos(language: str) -> List[str]:\n",
    "    repos = []\n",
    "    for page in range(1, 4):  # GitHub uses 1-indexed pages\n",
    "        url = f\"https://github.com/search?spoken_language_code=en&o=desc&q=stars%3A%3E1+language%3A{language}&s=forks&type=Repositories&l={language}&p={page}\"\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        repos += [repo.get('href')[1:] for repo in soup.select('.v-align-middle') if repo.get('href')]\n",
    "        if len(repos) >= 100:\n",
    "            break\n",
    "        time.sleep(3)  # sleep between requests to respect rate limits\n",
    "    return repos[:100]\n",
    "\n",
    "\n",
    "def process_repo(repo: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Takes a repo name like \"gocodeup/codeup-setup-script\" and returns a\n",
    "    dictionary with the language of the repo and the readme contents.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"repo\": repo,\n",
    "        \"language\": get_repo_language(repo),\n",
    "        \"readme_contents\": get_readme_contents(repo),\n",
    "    }\n",
    "\n",
    "\n",
    "def scrape_github_data() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loop through all of the repos and process them. Returns the processed data in a DataFrame.\n",
    "    \"\"\"\n",
    "    languages = ['JavaScript', 'Python', 'Java', 'C']\n",
    "    data = []\n",
    "    for language in languages:\n",
    "        repos = get_top_100_repos(language)\n",
    "        for repo in repos:\n",
    "            data.append(process_repo(repo))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# run the scraping function and save the result to a CSV\n",
    "data = scrape_github_data()\n",
    "data.to_csv(\"github_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aef84b3a-0095-46c8-a1a0-20bcd40034c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('github_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cedfc0ae-1e47-4c27-93ed-f85144d3764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare.transform_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0811ca63-638c-49b2-ba81-b36fe5e1cb29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "repo          0\n",
       "language      1\n",
       "original      0\n",
       "clean         0\n",
       "stemmed       0\n",
       "lemmatized    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b140395-3b0a-494f-9043-708b0e13c699",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6ec3c88-d37f-4fca-98a3-955bec908734",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('combined_data_ready.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd618b44-0f90-4c18-881e-eed1e4be9116",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
